{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.feature import peak_local_max\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Feature Extraction Definitions\n",
    "def extract_spot_features(path):\n",
    "\n",
    "  # ------------------------------\n",
    "  # Image processing\n",
    "  # ------------------------------\n",
    "\n",
    "  ### import\n",
    "\n",
    "  data = io.imread(path)\n",
    "  [n_images, length, width] = np.shape(data)\n",
    "\n",
    "  # ------------------------------\n",
    "  # Feature extraction\n",
    "  # ------------------------------\n",
    "\n",
    "  ### timestamp for non-temporal features\n",
    "  t = 90\n",
    "\n",
    "  # Area, count, and fluorescence over time\n",
    " \n",
    "  maxima = [peak_local_max(data[n, :,:], min_distance=2, threshold_rel= .01, threshold_abs=150) for n in range(n_images)]\n",
    "  n_spots_over_time = [len(m) for m in maxima]\n",
    "  thresh = 150\n",
    "  area_over_time = [np.sum(data[t] > thresh) / (length * width) for t in range(n_images)]\n",
    "  bulk_fluorescence_over_time = [np.mean(data[t]) for t in range(n_images)]\n",
    "\n",
    "  ### timestamp for non-temporal features\n",
    "  t = 90\n",
    "\n",
    "  ### spot count\n",
    "  n_spots = n_spots_over_time[t]\n",
    "  max_n_spots = max(n_spots_over_time)\n",
    "\n",
    "  ### bulk fluorescence\n",
    "  bulk_fluorescence = bulk_fluorescence_over_time[t]\n",
    "\n",
    "  ### percent area\n",
    "  percent_area = area_over_time[t] if n_spots > 0 else 0\n",
    "\n",
    "  ### spot size (total pixel area w/ signal above threshold)\n",
    "  avg_spot_size = percent_area / n_spots if n_spots > 0 else 0\n",
    "\n",
    "  ### time to threshold\n",
    "  try:\n",
    "    # time_to_threshold = [np.max(data[t,:,:]) >= 5 for t in range(n_images)].index(True)\n",
    "    time_to_threshold = np.argmax(n_spots_over_time)/3\n",
    "  except ValueError:\n",
    "    time_to_threshold = n_images\n",
    "\n",
    "  ### max rate of change of spot count over 10 seconds\n",
    "  spot_counts_trimmed = [x for x in n_spots_over_time if x != 0]\n",
    "  spot_count_deltas = [spot_counts_trimmed[i + 10] - spot_counts_trimmed[i] for i in range(len(spot_counts_trimmed) - 10)]\n",
    "  max_spot_change = max(spot_count_deltas) if len(spot_count_deltas) > 0 else 0\n",
    "\n",
    "  ### max rate of change of spot area over 10 seconds\n",
    "  area_deltas = [area_over_time[i + 10] - area_over_time[i] for i in range(len(area_over_time) - 10)]\n",
    "  max_area_change = max(area_deltas) if len(area_deltas) > 0 else 0\n",
    "\n",
    "  ### max rate of change of bulk fluorescence over 10 seconds\n",
    "  fluorescence_deltas = [bulk_fluorescence_over_time[i + 10] - bulk_fluorescence_over_time[i] for i in range(len(bulk_fluorescence_over_time) - 10)]\n",
    "  max_fluorescence_change = max(fluorescence_deltas) if len(fluorescence_deltas) > 0 else 0\n",
    "\n",
    "  # construct features map\n",
    "\n",
    "  features = {\n",
    "      \"n_spots\": n_spots,\n",
    "      \"max_n_spots\": max_n_spots,\n",
    "      \"bulk_fluorescence\": bulk_fluorescence,\n",
    "      \"avg_spot_size\": avg_spot_size,\n",
    "      \"percent_area\": percent_area,\n",
    "      \"time_to_threshold\": time_to_threshold,\n",
    "      \"max_spot_change\": max_spot_change,\n",
    "      \"max_area_change\": max_area_change,\n",
    "      \"max_fluorescence_change\": max_fluorescence_change\n",
    "  }\n",
    "\n",
    "  # for i in range(240, n_images, 60):\n",
    "  #   features[f\"n_spots_{i}\"] = n_spots_over_time[i]\n",
    "  #   features[f\"bulk_fluorescence_{i}\"] = bulk_fluorescence_over_time[i]\n",
    "  #   features[f\"percent_area_{i}\"] = area_over_time[i] if n_spots > 0 else 0\n",
    "\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Experiments\n",
    "dir = r\"../RPA on glass slides/100_serial/processed\"\n",
    "\n",
    "\n",
    "experiments = {\n",
    "    \"0\": [\n",
    "        '0-1.tif',\n",
    "        '0.tif'\n",
    "    ],\n",
    "    \"1000\": [\n",
    "        '1000.tif',\n",
    "        '1000-1.tif',\n",
    "        '1000-2.tif'\n",
    "    ],\n",
    "    \"10000\": [\n",
    "        '10000-2.tif',\n",
    "        '10000-1.tif',\n",
    "        '10000.tif'\n",
    "\n",
    "    ],\n",
    "    \"100000\": [\n",
    "        '100000-1.tif',\n",
    "        '100000.tif'\n",
    "    ],\n",
    "    \"20\": [\n",
    "        '20.tif'\n",
    "    ],\n",
    "    \"200\": [\n",
    "        '200-1.tif',\n",
    "        '200-2.tif',\n",
    "        '200.tif'\n",
    "\n",
    "    ],\n",
    "    \"2000\": [\n",
    "        '2000-1.tif',\n",
    "        '2000.tif'\n",
    "\n",
    "    ],\n",
    "    \"3000\": [\n",
    "        '3000.tif'\n",
    "\n",
    "    ],\n",
    "    \"30000\": [\n",
    "        '30000-1.tif',\n",
    "        '30000-2.tif',\n",
    "        '30000-3.tif',\n",
    "        '30000-4.tif',\n",
    "        '30000.tif'\n",
    "\n",
    "    ],\n",
    "    \"5000\": [\n",
    "        '5000-1.tif',\n",
    "        '5000-2.tif',\n",
    "        '5000-3.tif',\n",
    "        '5000-4.tif',\n",
    "        '5000-5.tif',\n",
    "        '5000.tif'\n",
    "\n",
    "    ],\n",
    "\n",
    "    \"40\": [\n",
    "        '40.tif'\n",
    "\n",
    "    ],\n",
    "    \"500\": [\n",
    "        '500-1.tif',\n",
    "        '500.tif'\n",
    "\n",
    "    ],\n",
    "    \"50000\": [\n",
    "        '50000-1.tif',\n",
    "        '50000.tif'\n",
    "\n",
    "    ],\n",
    "\n",
    "    \"80\": [\n",
    "        '80.tif'\n",
    "\n",
    "    ],\n",
    "    \"8000\": [\n",
    "        '8000-1.tif',\n",
    "        '8000.tif'\n",
    "\n",
    "    ],\n",
    "    \"80000\": [\n",
    "        '80000-1.tif',\n",
    "        '80000.tif'\n",
    "\n",
    "    ]\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CDM\\miniconda3\\envs\\ANSA_new\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_spots</th>\n",
       "      <th>max_n_spots</th>\n",
       "      <th>bulk_fluorescence</th>\n",
       "      <th>avg_spot_size</th>\n",
       "      <th>percent_area</th>\n",
       "      <th>time_to_threshold</th>\n",
       "      <th>max_spot_change</th>\n",
       "      <th>max_area_change</th>\n",
       "      <th>max_fluorescence_change</th>\n",
       "      <th>copy_number</th>\n",
       "      <th>log_copy_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>537</td>\n",
       "      <td>576</td>\n",
       "      <td>56.066792</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.152094</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>264</td>\n",
       "      <td>0.062094</td>\n",
       "      <td>22.959905</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>281</td>\n",
       "      <td>293</td>\n",
       "      <td>74.177323</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.132277</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>123</td>\n",
       "      <td>0.042786</td>\n",
       "      <td>25.343478</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>236</td>\n",
       "      <td>260</td>\n",
       "      <td>35.715783</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.076926</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>106</td>\n",
       "      <td>0.030125</td>\n",
       "      <td>14.762014</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>476</td>\n",
       "      <td>482</td>\n",
       "      <td>133.732320</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.229381</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>239</td>\n",
       "      <td>0.079694</td>\n",
       "      <td>36.214404</td>\n",
       "      <td>10000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>513</td>\n",
       "      <td>531</td>\n",
       "      <td>128.079893</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.239780</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>289</td>\n",
       "      <td>0.085354</td>\n",
       "      <td>36.735576</td>\n",
       "      <td>10000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_spots  max_n_spots  bulk_fluorescence  avg_spot_size  percent_area  \\\n",
       "2      537          576          56.066792       0.000283      0.152094   \n",
       "3      281          293          74.177323       0.000471      0.132277   \n",
       "4      236          260          35.715783       0.000326      0.076926   \n",
       "5      476          482         133.732320       0.000482      0.229381   \n",
       "6      513          531         128.079893       0.000467      0.239780   \n",
       "\n",
       "   time_to_threshold  max_spot_change  max_area_change  \\\n",
       "2          34.000000              264         0.062094   \n",
       "3          41.666667              123         0.042786   \n",
       "4          41.666667              106         0.030125   \n",
       "5          31.000000              239         0.079694   \n",
       "6          27.666667              289         0.085354   \n",
       "\n",
       "   max_fluorescence_change copy_number  log_copy_number  \n",
       "2                22.959905        1000              3.0  \n",
       "3                25.343478        1000              3.0  \n",
       "4                14.762014        1000              3.0  \n",
       "5                36.214404       10000              4.0  \n",
       "6                36.735576       10000              4.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Extract Features to CSV\n",
    "\n",
    "features_csv = \"structured_data.csv\"\n",
    "\n",
    "if not os.path.exists(features_csv):\n",
    "  features = {}\n",
    "\n",
    "  for n_copies in experiments:\n",
    "    features[n_copies] = []\n",
    "    for exp in experiments[n_copies]:\n",
    "      image_stack = os.path.join(dir, n_copies, exp)\n",
    "      features[n_copies].append(extract_spot_features(image_stack))\n",
    "\n",
    "  # Parse the data into a DataFrame\n",
    "  data = []\n",
    "  for copy_number, records in features.items():\n",
    "      for record in records:\n",
    "          record['copy_number'] = copy_number\n",
    "          data.append(record)\n",
    "\n",
    "  df = pd.DataFrame(data)\n",
    "\n",
    "  # Convert copy numbers to log scale\n",
    "  df['log_copy_number'] = df['copy_number'].replace({'cps': '', ',': ''}, regex=True).astype(float)\n",
    "  df['log_copy_number'] = np.log10(df['log_copy_number'])\n",
    "\n",
    "  df.to_csv(features_csv, index=False)\n",
    "else:\n",
    "  df = pd.read_csv(features_csv)\n",
    "\n",
    "df.replace(-np.inf, np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse583",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
